{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import datasets_loader\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(max_raw_len, max_token_len, batch_size):\n",
    "\n",
    "    train_data = datasets_loader.get_dataset(\n",
    "            dataset_name=\"bigcode/the-stack-march-sample\",\n",
    "            path_to_cache=\"/mnt/colab_public/datasets/joao/bigcode/the-stack-march-sample\",\n",
    "            split=\"train\",\n",
    "            maximum_raw_length=max_raw_len,\n",
    "        )\n",
    "    \n",
    "    collate_fn = datasets_loader.Collator(\n",
    "        tokenizer_path=\"bigcode/tokenizer-the-stack-march-sample\",\n",
    "        maximum_length=max_token_len,\n",
    "        mlm_masking_probability=0.15,\n",
    "        contrastive_masking_probability=0.3,\n",
    "        ignore_contrastive_loss_data=True,\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_fraction_series(max_raw_len, max_token_len, batch_size):\n",
    "\n",
    "    loader = get_loader(max_raw_len, max_token_len, batch_size)\n",
    "\n",
    "    padding_ratio_series = []\n",
    "\n",
    "    for batch in loader:\n",
    "        input_ids = batch[0]\n",
    "        padding_count = (input_ids==loader.collate_fn.pad_token_id).float().sum()\n",
    "        padding_ratio_series.append(padding_count/input_ids.numel())\n",
    "    \n",
    "    return padding_ratio_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_raw_len_list = [1000, 5000, 10000, 20000, 50000]\n",
    "max_token_len_list = [512, 784, 1024, 2048, 4096]\n",
    "batch_size = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf08dbcf233840c888ae142d29f7e17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Token len:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf46283f3641a3a1c574caa73753b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Raw len:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/mnt/colab_public/datasets/joao/bigcode/the-stack-march-sample/bigcode___parquet/bigcode--the-stack-march-sample-ba0d1a1a229e8720/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f7824292a248a2a844b4424f675b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/colab_public/datasets/joao/bigcode/the-stack-march-sample/bigcode___parquet/bigcode--the-stack-march-sample-ba0d1a1a229e8720/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8516320185f20da3.arrow\n",
      "Found cached dataset parquet (/mnt/colab_public/datasets/joao/bigcode/the-stack-march-sample/bigcode___parquet/bigcode--the-stack-march-sample-ba0d1a1a229e8720/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b6e51903af4c9397c462800b9175fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/colab_public/datasets/joao/bigcode/the-stack-march-sample/bigcode___parquet/bigcode--the-stack-march-sample-ba0d1a1a229e8720/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-85e33cff9f85f34b.arrow\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for max_token_len in tqdm.notebook.tqdm(max_token_len_list, desc=\"Token len\"):\n",
    "    for max_raw_len in tqdm.notebook.tqdm(max_raw_len_list, desc=\"Raw len\"):\n",
    "        padding_fraction_series = get_token_fraction_series(max_raw_len, max_token_len, batch_size)\n",
    "\n",
    "        try:\n",
    "            results_dict[max_token_len][max_raw_len] = padding_fraction_series\n",
    "        except KeyError:\n",
    "            results_dict[max_token_len] = {max_raw_len: padding_fraction_series}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_interval(data_series):\n",
    "    def ci95(seq):\n",
    "        return 1.96 * np.std(seq) / np.sqrt(len(seq))\n",
    "    return np.mean(data_series), ci95(data_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor=\"white\")\n",
    "for max_token_len in max_token_len_list:\n",
    "    ci_center_series = []\n",
    "    ci_extrema_series = []\n",
    "    for max_raw_len in max_raw_len_list:\n",
    "        center, error = get_confidence_interval(results_dict[max_token_len][max_raw_len])\n",
    "\n",
    "        ci_center_series.append(center)\n",
    "        ci_extrema_series.append(error)\n",
    "        \n",
    "    plt.plot(max_raw_len_list, ci_center_series, label=f\"Max len: {max_token_len}\")\n",
    "    plt.errorbar(max_raw_len_list, ci_center_series, yerr=ci_extrema_series, fmt ='o')\n",
    "\n",
    "plt.xlabel = \"Max input length\"\n",
    "plt.ylabel = \"Padding fraction\"\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae635839a86c404533bb974203baf1bd26d9dc49bfbf145b45e9350c30045fdd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('accelerate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
